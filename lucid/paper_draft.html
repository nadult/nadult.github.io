<html><head><link rel="stylesheet" type="text/css" href="https://nadult.github.io/lucid/plaintext.css"><link rel="stylesheet" type="text/css" href="https://nadult.github.io/lucid/index.css"></head><body data-new-gr-c-s-check-loaded="8.908.0" data-gr-ext-installed=""><link rel="stylesheet" type="text/css" href="https://nadult.github.io/lucid/github.css" id="_theme"><div id="_html" class="markdown-body"><h1 id="lucidraster-real-time-gpu-software-rasterizer-for-exact-order-independent-transparency-draft"><a class="anchor" name="lucidraster-real-time-gpu-software-rasterizer-for-exact-order-independent-transparency-draft" href="#lucidraster-real-time-gpu-software-rasterizer-for-exact-order-independent-transparency-draft"><span class="octicon octicon-link"></span></a>LucidRaster: Real-time GPU software rasterizer for exact order-independent transparency [DRAFT]</h1>
<p><strong>Author: Krzysztof Jakubowski</strong><br><strong>Contact: nadult (at) fastmail (dot) fm</strong></p>
<h2 id="abstract"><a class="anchor" name="abstract" href="#abstract"><span class="octicon octicon-link"></span></a>Abstract</h2>
<p>Transparency rendering is problematic and can be considered an open problem in real-time graphics. There are many different algorithms currently available, but handling complex scenes and achieving accurate, glitch-free results is still costly.</p>
<p>This paper describes LucidRaster: a software rasterizer running on GPUs which allows for efficient exact rendering of complex transparent scenes. It uses a new two-stage sorting technique and sample accumulation method. On average it's faster than high-quality OIT approximations and only about 3x slower than hardware alpha blending. It can be very efficient especially when rendering scenes with high triangle density or high depth complexity.</p>
<p>LucidRaster source code is available at GitHub: <a href="https://github.com/nadult/lucid"></a><a href="https://github.com/nadult/lucid">https://github.com/nadult/lucid</a></p>
<h2 id="1-introduction"><a class="anchor" name="1-introduction" href="#1-introduction"><span class="octicon octicon-link"></span></a>1. Introduction</h2>
<p>Rendering 3D scenes with transparent surfaces can be problematic. Graphics hardware for a long time had support for blending transparent surfaces, but those surfaces had to be sorted first. In general, order-independent transparency (OIT) techniques allow for rendering transparent scenes without this requirement. Exact OIT algorithm has to identify all the fragments which contribute to a given pixel, sort them and blend them in the correct order. Good examples of exact OIT algorithms are: a-buffer <a href="#refs-carpenter-1984">[Carpenter 1984]</a>, depth peeling <a href="#refs-everitt-2001">[Everitt 2001]</a>. Advanced algorithms which utilize backwards memory allocation <a href="#refs-knowles-2013">[Knowles 2013]</a> and improved sorting techniques <a href="#refs-knowles-2014">[Knowles 2014]</a> can provide big performance improvements.</p>
<p>Still, exact OIT techniques are about an order of magnitude slower than unsorted hardware alpha-blending. Approximate OIT techniques fill the performance gap between the two. Weighted-blended OIT <a href="#refs-mcguire-2013">[McGuire 2013]</a> is only about 20% slower than hardware rendering. Moment-based OIT <a href="#refs-peters-2018">[Peters 2018]</a> is significantly costlier than WBOIT, but provides a much better approximation.</p>
<p>Two surveys cover a wide range of OIT algorithms: "A Survey of Multifragment Rendering" <a href="#refs-vasilakis-2020">[Vasilakis 2020]</a> and "Exploring and Expanding the Continuum of OIT Algorithms" <a href="#refs-wyman-2016">[Wyman 2016]</a>. </p>
<p>With each next generation, GPUs become more and more feasible for general-purpose computations. Current GPUs already allow for the efficient implementation of software rasterizers. There are several interesting examples available. CudaRaster <a href="#refs-laine-2011">[Laine 2011]</a> and cuRE <a href="#refs-kenzel-2018">[Kenzel 2018]</a> are a general-purpose rasterizers. FreePipe <a href="#refs-liu-2010">[Liu 2010]</a> similarly to LucidRaster has a focus on multi-fragment effects. All three of these rasterizers are several times slower than hardware with CudaRaster being the fastest. Nanite <a href="#refs-karis-2021">[Karis 2021]</a> uses a simple software micro-poly rasterizer which can be up to 3x faster than a general-purpose GPU rasterizer.</p>
<p>Most of the OIT algorithms are built around a hardware rasterizer, which is used for the accumulation and / or composition of fragments. There were successful attempts at using compute shaders for sprite rendering <a href="#refs-kohler-2016">[KÃ¶hler 2016]</a>, but in general, the core computation in a typical OIT algorithm happens in a fragment shader. This is a major restriction which limits the potential efficiency of OIT algorithms. LucidRaster is an attempt to break this restriction by implementing a software rasterizer which is tailored for the purpose of transparency rendering.</p>
<p>LucidRaster performance is evaluated by comparing it with a simple hardware-based unsorted alpha-blended renderer. Moment-based OIT paper <a href="#refs-kenzel-2018">[Kenzel 2018]</a> contains a similar comparison which allows to compare (roughly) several different OIT algorithms:</p>
<table style="text-align:right; font-family: monospace; font-size:0.8em;">
  <tbody><tr> <th>Algorithm</th> <th>Parameters</th> <th>Relative running time</th> </tr>
  <tr> <td>Hardware alpha blending</td>      <td></td>                                  <td>1.00</td> </tr>
  <tr> <td>Weighted-blended OIT</td>         <td></td>                                  <td>1.17</td> </tr>
  <tr> <td>Multi-layer alpha blending</td>   <td>2 layers</td>                          <td>2.78</td> </tr>
  <tr> <td>Multi-layer alpha blending</td>   <td>4 layers</td>                          <td>4.75</td> </tr>
  <tr> <td>Moment based OIT</td>             <td>4 power moments, 80 bits</td>          <td>2.64</td> </tr>
  <tr> <td>Moment based OIT</td>             <td>6 power moments, 112 bits</td>         <td>3.13</td> </tr>
  <tr> <td>Moment based OIT</td>             <td>4 trigonometric moments, 144 bits</td> <td>5.00</td> </tr>
  <tr> <td>LucidRaster</td>                  <td></td>                                  <td>3.30</td> </tr>
</tbody></table>

<p>Performance values for WBOIT, MLAB and MBOIT are averages, relative to hardware alpha blending, taken from Moment-based OIT paper. The performance value for LucidRaster is an average computed from SW/HW values for all scenes and all tested GPUs. Because algorithms were tested in different environments, this table can provide only a very rough idea about the performance differences between previous OIT algorithms and LucidRaster.</p>
<p>Work on LucidRaster was completely self-funded and because of limited resources, I tried to create a minimal rasterizer which demonstrates the usefulness of this technique. The main limitations / areas of improvement are high memory usage, support for single, simple uber-material, no MSAA support and limited rendering resolution.</p>
<h2 id="2-pipeline-description"><a class="anchor" name="2-pipeline-description" href="#2-pipeline-description"><span class="octicon octicon-link"></span></a>2. Pipeline description</h2>
<p>LucidRaster is built around several core ideas:</p>
<ul>
<li>Sort-middle <a href="#refs-molnar-1994">[Molnar 1994]</a> pipeline where triangles are first distributed into small evenly-sized bins. This allows for sorting and merging of all fragments in a given bin in shared memory, which can save a lot of framebuffer bandwidth.</li>
<li>Two-stage sorting: depth-sorting blocks of fragments (8x4 or 8x8) coupled with per-pixel fixed-size fragment sorter.</li>
<li>Taking quads as input instead of triangles. This allows to save bandwidth and reduces processing time in the initial pipeline stages.</li>
</ul>
<p>LucidRaster pipeline is comprised of three stages:</p>
<ul>
<li>Setup stage: input primitives are tested for visibility. For each visible triangle, shading and rasterization data are computed and stored.</li>
<li>Binning stage: the screen is divided into 32x32-pixel bins and for each bin a list of overlapping primitives is created.</li>
<li>Rasterization stage: bins are rasterized one by one: triangles in each bin are sorted, samples are generated, blended together and written to the framebuffer.</li>
</ul>
<p>LucidRaster pipeline is quite similar to cuda-raster <a href="#refs-laine-2011">[Laine 2011]</a>.<br>The paper describing this rasterizer is a good introduction into software rasterization on GPUs.</p>
<h3 id="stage-1-quad-setup"><a class="anchor" name="stage-1-quad-setup" href="#stage-1-quad-setup"><span class="octicon octicon-link"></span></a>Stage 1: Quad setup</h3>
<p>Essentially setup stage takes a stream of input quads, it culls those which do not contribute to the final image and pre-compute some data for those which are visible. Pre-computed data will be used in later pipeline stages.</p>
<p>Input quads are divided into chunks of up to 1024 primitives which have the same material. Each chunk is processed by a different <a href="#glossary-workgroup">workgroup</a>, which is also sized to 1024 threads. Quad chunks are processed in two phases with compacting step happening between them. The first phase culls invisible quads; the second one does the pre-computation and storage.</p>
<h4 id="phase-1-processing-input-quads"><a class="anchor" name="phase-1-processing-input-quads" href="#phase-1-processing-input-quads"><span class="octicon octicon-link"></span></a>Phase 1: processing input quads</h4>
<p>Each thread handles one input quad. It loads its vertex indices and if both tris which comprise a quad are degenerate, then the whole quad is culled. Vertex positions are loaded and if backface culling is enabled, each triangle is tested (in world space) whether its back or front is facing the camera and if both triangles are back-facing then the quad is culled. Next, quad vertices are transformed to NDC space and vertices are tested if they are on the visible side of the clipping planes. If all vertices are on the outer side of at least one of the clipping planes then the quad is culled.</p>
<p>Because LucidRaster uses 3D rasterization <a href="#refs-davidovic-2012">[Davidovic 2012]</a>, full clipping is not required. This simplifies the setup stage, but screen-space AABBs still have to be computed. For that Jim Blinn's 'Calculating Screen Coverage' algorithm <a href="#refs-blinn-1996">[Blinn 1996]</a> is used. With AABBs computed, quads which fall between the rasterizer's sample positions can be detected and culled (<a href="#refs-laine-2011">[Laine 2011]</a> p 5.1). Finally, quads which weren't culled up until this point are considered visible. Those quads are classified as either small or large based on the number of bins which they overlap. If it's more than 4 then quad is classified as large.</p>
<p>Once all visible quads in a chunk are identified, they are compacted and space for them is allocated in <a href="#glossary-global-memory">global memory</a>. Compacting improves performance of the second phase in cases where large percentage of randomly distributed quads are culled. Shared memory is used to transfer visible quads' data from the first phase to the second phase to avoid recomputation. For example, AABBs encoded in single uint are transferred this way.</p>
<h4 id="phase-2-writing-primitives-data"><a class="anchor" name="phase-2-writing-primitives-data" href="#phase-2-writing-primitives-data"><span class="octicon octicon-link"></span></a>Phase 2: writing primitives data</h4>
<p>In this phase for each visible quad, shading &amp; rasterization data are computed and stored in global memory. Different pre-computed quad attributes are put into different storages. This division is based on the way the data will be accessed later in the pipeline: attributes which are read together are stored together. Some attributes are computed and stored per-triangle, others per-quad. </p>
<p>Per-triangle attributes are put in 4 different storages with the following contents:</p>
<ul>
<li>Triangle normals (encoded as uint: X10Y10Z10)</li>
<li>Edge functions for barycentric coordinates (vec4[2])</li>
<li>Edge function for depth, instance flags and instance id (encoded in uvec4)</li>
<li>3D edge functions for scanline rasterizer, screen space AABB in the Y axis (encoded in uvec4[2])</li>
</ul>
<p>Per-quad attributes are put in 4 different storages with the following contents:</p>
<ul>
<li>bin-resolution AABBs for the whole quad and per-triangle culling info (as uint: 28 bits for AABB and 2 bits for culling info)</li>
<li>vertex colors (as uvec4, each color encoded in R8G8B8A8)</li>
<li>vertex normals (as uvec4, each normal encoded in X10Y10Z10)</li>
<li>vertex texture coordinates (as vec4[2])</li>
</ul>
<p>Per-quad vertex attributes are optional and are only stored if the quad's material actually needs them. They require almost no computation and are basically copied from vertex buffers, but when grouped together in per-quad storage they improve cache efficiency in the final rasterization phase and in effect improve performance of the whole pipeline.</p>
<h3 id="stage-2-quad-binning"><a class="anchor" name="stage-2-quad-binning" href="#stage-2-quad-binning"><span class="octicon octicon-link"></span></a>Stage 2: Quad binning</h3>
<p>Binning stage takes a flat stream of visible quads divided in two groups: small and large. At this stage, the main task is to generate a list of overlapping primitives for each bin. The secondary task is to categorize bins based on primitive density. Quad binning happens in 3 phases, each involving a separate compute shader dispatch.</p>
<h4 id="phase-1-counting-per-bin-primitives"><a class="anchor" name="phase-1-counting-per-bin-primitives" href="#phase-1-counting-per-bin-primitives"><span class="octicon octicon-link"></span></a>Phase 1: Counting per-bin primitives</h4>
<p>In this phase only as many workgroups are spawned as required to saturate all GPU cores. Workgroups work in a persistent threading <a href="#refs-gupta-2012">[Gupta 2012]</a> fashion: each in a loop tries to acquire and process a batch of primitives until all primitives are processed. Workgroups have to be large enough so that they could fit an array of 32-bit per-bin primitive counters in shared memory. With a resolution limit of 2560x2048 and with 32x32 bins there can be at most 5120 bins. Depending on the platform, 512 or 1024 threads per workgroup should be enough to hold this array in shared memory without negatively affecting occupancy.</p>
<p>The main goal in this phase is to count, for each bin, the number of overlapped primitives. Primitives are processed in batches. Because there are two types of primitives, there are also two types of batches: quad-batches which contain small quads and tri-batches with large triangles. Because small quads require very little processing, it's best to process more quads at once to minimize per-batch overhead. Tri-batches on the other hand usually take a lot more time to process, because rasterization is involved and the primitive surface area is larger. Additionally, in a typical scene, there aren't that many of them. So tri-batches are only large enough so that each thread in a workgroup has a single triangle to work on.</p>
<p>Quad-batches and tri-batches are processed separately: tri-batch processing starts only after all quad-batches have been processed. Each workgroup processes some number of batches of each type by counting (in a shared memory array) per-bin instances of overlapped primitives. To count small quads, only AABBs are used. It's not enough information to count accurately, but because small quads can overlap at most 2x2 bins, in most cases the estimate will be accurate. In the worst case, 1 bin out of 4 will be marked incorrectly as overlapped which will negligibly affect the rasterizer stage performance. For large triangles rasterization is used. Once there are no more batches of a given type to process, two things happen. First, all per-bin counters are atomically accumulated from all workgroups into a single array in global memory (BIN_QUAD_COUNTS for quads and BIN_TRI_COUNTS for triangles). Secondly, each workgroup saves to global memory a list of processed batches (a single number is sufficient to identify a batch) and per-bin counters array. In a way, it is a snapshot, which will allow to continue working on the same set of batches in the 3rd phase.</p>
<h4 id="phase-2-bin-categorization--offset-computation"><a class="anchor" name="phase-2-bin-categorization--offset-computation" href="#phase-2-bin-categorization--offset-computation"><span class="octicon octicon-link"></span></a>Phase 2: bin categorization &amp; offset computation</h4>
<p>Once the first phase is finished, BIN_QUAD_COUNTS and BIN_TRI_COUNTS arrays will contain primitive overlap counts for each bin. In this phase, these arrays are used to perform two tasks, each with a single workgroup. The first task is to compute offsets for primitive lists for each bin by applying prefix sum to per-bin primitive counts. Those offsets will be used in the next phase when storing indices of per-bin primitives. The second task is to categorize bins based on the number of overlapping triangles (quads are counted as 2 triangles). Currently, there are 3 categories: empty, low (for bins with less than 1024 triangles) and high (for bins with at least 1024 triangles).</p>
<h4 id="phase-3-writing-per-bin-primitive-lists"><a class="anchor" name="phase-3-writing-per-bin-primitive-lists" href="#phase-3-writing-per-bin-primitive-lists"><span class="octicon octicon-link"></span></a>Phase 3: Writing per-bin primitive lists</h4>
<p>The third phase is in many ways similar to the first. It runs the same number of workgroups. Each workgroup continues work from the first phase workgroup with the same id. 
It will generate per-bin primitive lists for the same primitives which were processed in the first phase (by using a previously saved batch list). Previously saved per-workgroup per-bin counters are used to allocate space in a global per-bin offsets array for primitive indices for all bins touched by selected batches. After allocation, in shared memory, in an array similar as in the first phase, global per-bin offsets are kept.</p>
<p>Quad-batches and tri-batches are processed separately, just like in the first phase. Processing primitives is also similar, but instead of counting, for each overlapped bin, an offset is computed by atomically incrementing a per-bin counter in shared memory and writing an appropriate primitive index to global memory. Large triangles may cause load-balancing problems, because surface area of different triangles may vary wildly. To deal with that, a simple balancing scheme is implemented: threads within a <a href="#glossary-subgroup">subgroup</a> try to equally divide between them to-be-written indices on a row level. This scheme is simple and can provide a solid performance boost on some scenes (phase 3 up to 2.5X faster).</p>
<p>It might be concerning that per-workgroup batch lists are inherited from phase 1 to phase 3. But in practice, it doesn't cause any load balancing problems across workgroups, because the amount of work which each workgroup has to perform in phase 1 is proportional to the amount of work in phase 3.</p>
<h4 id="triangle-rasterization"><a class="anchor" name="triangle-rasterization" href="#triangle-rasterization"><span class="octicon octicon-link"></span></a>Triangle rasterization</h4>
<p>The triangle scanline rasterization algorithm which is used in LucidRaster is similar to micropoly software rasterizer used in Nanite <a href="#refs-karis-2021">[Karis 2021]</a> with the main difference that 3D rasterization <a href="#refs-davidovic-2012">[Davidovic 2012]</a> is also used. Basically, for a given triangle it iterates over all rows of its screen-space AABB. In each row instead of testing each pixel, it computes (in constant time) an interval of overlapped pixels. 3D edge functions with parameters precomputed during the setup stage are used.</p>
<p>There are two versions of the scanline algorithm: one which works on pixels (which is used in the final rasterization stage) and another which works on 32x32-pixel bins (this one is used in binning stage). The bin version is also optimized with a simple 'trivial reject test' <a href="#refs-abrash-2009">[Abrash 2009]</a>.</p>
<h3 id="stage-3-bin-rasterization"><a class="anchor" name="stage-3-bin-rasterization" href="#stage-3-bin-rasterization"><span class="octicon octicon-link"></span></a>Stage 3: Bin rasterization</h3>
<p>During the bin rasterization stage, 32x32-pixel bins are further divided into smaller regions: 32x8-pixel block-rows, 8x8-pixel blocks and 8x4-pixel half-blocks. All of these are fixed on a grid: block-rows on 1x4 grid (4 total), blocks on 4x4 grid (16 total) and half-blocks on 4x8 grid (32 total). Per-triangle pixel coverage information can be generated for all of those. Let's name data structures that hold per-triangle pixel coverage information: Tri-block-row for block-rows, tri-block for blocks and tri-half-block for half-blocks.</p>
<p>LucidRaster handles bins with low and high densities of triangles with two different compute shaders: low-rasterizer and high-rasterizer. The low-density version besides the limit on the number of triangles per bin also has limits on the number of fragments and triangles per block and per block-row. Those limits allow for more efficient processing but can be too constraining for some, albeit very small, percentage of bins. Such bins are detected in low-rasterizer and are propagated to high-rasterizer (which has much weaker constraints). Because of that high-rasterizer workgroups are dispatched only after the low-rasterizer has finished. What follows is a description of the low-rasterizer; the differences between the two versions are described afterwards.</p>
<p>Similarly to the binning stage, persistent threads are used in this stage as well. Each workgroup in a loop tries to acquire and rasterize a bin until all bins are processed. Again, only as many workgroups are spawned as required to saturate all GPU cores. Low-rasterizer uses workgroups containing 256 threads each.</p>
<p>Bin rasterization happens in three phases:</p>
<ul>
<li>Phase 1: Block-row generation: arrays of tri-block-rows are generated.</li>
<li>Phase 2: Half-block extraction: depth-sorted tri-half-blocks are extracted from tri-block-rows.</li>
<li>Phase 3: Shading &amp; blending: tri-half-blocks are shaded, blended together and written to the output framebuffer.</li>
</ul>
<h4 id="phase-1-tri-block-row-generation"><a class="anchor" name="phase-1-tri-block-row-generation" href="#phase-1-tri-block-row-generation"><span class="octicon octicon-link"></span></a>Phase 1: tri-block-row generation</h4>
<p>Phase 1 begins with processing all per-bin small quads and large triangles. Quads are further divided into triangles, and triangles are processed directly. For each triangle, scanline algorithm is used to generate intervals of covered pixels for each row within 32x8-pixel block-rows. Per-triangle scanline data includes minimum &amp; maximum Y coordinates, which allows the scanline algorithm to iterate only over block-rows with not-empty intervals. Tri-block-row pixel coverage information can be efficiently encoded in less than 128 bits: <code>(5 + 5) * 8 = 80</code> bits for per-row pixel intervals, 4 bits for block column coverage and 24 bits for visible triangle index. This information is saved in a per-workgroup scratch buffer stored in global memory. Tri-block-rows belonging to different block-rows are stored separately in 4 different arrays. Because of the limit on the number of triangles per block-row (1024), the size of a per-workgroup scratch buffer can be kept relatively low. Shared memory atomics are used for counting tri-block-rows.</p>
<h4 id="phase-2-half-block-extraction"><a class="anchor" name="phase-2-half-block-extraction" href="#phase-2-half-block-extraction"><span class="octicon octicon-link"></span></a>Phase 2: half-block extraction</h4>
<p>The goal in this phase is to generate, for all half-blocks within the current bin, a depth-sorted list of tri-half-blocks.</p>
<p>Subgroups process all blocks within a current bin one after another. Subgroups work independently, each working on a single block at the time. Each subgroup will generate two arrays of tri-half-blocks in a scratch buffer in global memory. In both cases, tri-blocks will be generated, sorted and in the end divided into two halves.</p>
<p>Efficient use of shared memory is the key to efficiency in this phase. Each subgroup has at its disposal 8 uints per thread (256 uints total for 32 threads). In the low-rasterizer, the upper limit on the number of triangles per block is 256, which allows to perform most of the processing (especially sorting) without constantly writing/reading to/from global memory.</p>
<p>Subgroups start by first identifying which tri-block-rows overlap the current block. Block column coverage bits are used for that. Each subgroup generates in shared memory a list of tri-block-row indices. The easiest way to do it (and also quite efficient) is to simply iterate over all tri-block-rows and for those which overlap the current block, use an atomic counter to compute an index and count them at the same time.</p>
<p>To generate a sorted tri-block list, depth values are needed as well. So, subgroups iterate over tri-block-row index lists, compute tri-block sample centroids and depth values from those. Depth values together with tri-block index (which is identical to tri-block-row index) are encoded into a single 32-bit uint and stored in shared memory. 22 high bits are used for depth, 10 low bits are used for tri-block-index. Those values are then sorted with bitonic sort optimized with subgroup shuffles <a href="#refs-demouth-2013">[Demouth 2013]</a>. Tri-blocks are sorted front to back.</p>
<p>At the end of the phase each subgroup iterates over sorted tri-block indices, generates two arrays of tri-half-blocks and stores them in scratch buffer in global memory. Tri-half-blocks contain:</p>
<ul>
<li>Pixel coverage information (`(3 + 3) * 4 = 24 bits).</li>
<li>Visible triangle index (24 bits).</li>
<li>Fragment count prefix sum (only 12 lower bits are needed). This value is used in the next phase to quickly compute an index for each sample.</li>
</ul>
<h4 id="phase-3-shading--blending"><a class="anchor" name="phase-3-shading--blending" href="#phase-3-shading--blending"><span class="octicon octicon-link"></span></a>Phase 3: shading &amp; blending</h4>
<p>Once the rasterizer gets to phase 3, data required to efficiently render samples in half-blocks will be available in a scratch buffer in global memory. Now subgroups will independently shade &amp; blend each half-block. LucidRaster currently works only on GPUs which have subgroups containing 32 or 64 threads. In the case of 64-thread subgroup, two half-blocks are processed at the same time by a single subgroup.</p>
<p>All samples in a given half-block are ordered. Samples coming from different triangles are ordered in the same way as tri-half-blocks and as for the samples coming from the same triangle, they are ordered row-by-row, with top-left sample being first and bottom-right being last. Samples are additionally grouped in segments, where each segment can contain at most 256 samples. All segments except the last one will be full and contain 256 samples.</p>
<p>Subgroups in a loop process samples in segments, one segment at a time. Each thread within a subgroup is responsible for a single pixel: it keeps the current RGBA color (initially fully transparent black) and depth filter context. This context contains a constant size (currently 3) of depth-color pairs. Depth filter allows for fixing invalid depth order of samples which may happen when tri-half-blocks sample depths overlap. It cannot fix all depth-order issues, but it handles the vast majority of cases. Increasing depth-filter size allows for solving more complex ordering issues, but increases register pressure and decreases overall performance.</p>
<p>Each thread in a subgroup takes a single sample from a segment and shades it. After shading those samples are immediately blended with previously blended samples. Sample color &amp; depth has to be transferred to the appropriate thread based on the sample position. It can be done efficiently with bitwise operations and subgroup shuffles: after shading each thread atomically writes a single bit to a 32x32-bit array in shared memory. Bit position encodes sample position within half-block and thread-id. Afterwards, each thread iterates in-order over all samples which overlap the pixel position assigned to the current thread. Those samples are then blended with those which were processed previously.</p>
<p>Once all samples are processed, threads write the colors to the framebuffer. The workgroup can then proceed to the next bin.</p>
<h5 id="sample-shading"><a class="anchor" name="sample-shading" href="#sample-shading"><span class="octicon octicon-link"></span></a>Sample shading</h5>
<p>In LucidRaster simple fragment shader is used to demonstrate the basic capabilities of the rasterizer. Shader supports vertex normals &amp; colors, single texture per triangle and performs simple lighting calculation. To support mip-mapping, texture coordinate gradients are required. Instead of using quad-shading, analytic derivatives are computed. This allows for more efficient processing of tiny triangles. To support multiple textures in a given scene, texture atlases are used. </p>
<h5 id="sample-blending"><a class="anchor" name="sample-blending" href="#sample-blending"><span class="octicon octicon-link"></span></a>Sample blending</h5>
<p>Samples, before being blended into the final result, first have to pass through the depth-filter. This filter is basically a fixed-size priority queue, in which samples are ordered by depth. Whenever a new sample is added to the stack, one of the samples falls out and is blended into the target result.</p>
<p>By increasing the depth-filter size by 1, pixels with incorrectly ordered samples can also be detected. Those pixels could be registered and afterwards processed by a slower, conservative algorithm. In most scenes less than 0.1% of pixels are invalid. In the most problematic scenes, it's between 0.5% - 1%. Those errors can be prevented by fixing the geometry (for example in white-oak and san-miguel scenes foliage is especially problematic, but intersections in foliage geometry are not required to achieve a satisfactory result) or by increasing depth-filter size. For example number of invalid pixels in white-oak scene can be decreased from 1% to 0.08% by increasing the depth-filter size from 3 to 8. This slows down the whole rendering performance by 1.5%.</p>
<p>Blending is performed front to back. This allows for a simple, but efficient optimization. When accumulated alpha approaches 1.0, then further samples can be discarded, because their contribution will be minimal. In LucidRaster this optimization can be enabled with 'alpha_threshold' flag. When enabled, shading &amp; blending stops once all pixels within a half-block have accumulated at least <code>1 - 1 / 128</code> alpha value.</p>
<h3 id="high-rasterizer"><a class="anchor" name="high-rasterizer" href="#high-rasterizer"><span class="octicon octicon-link"></span></a>High-rasterizer</h3>
<p>High-rasterizer is very similar to the low-rasterizer, but it has to be able to process a lot more triangles per-bin than the low-rasterizer. The main differences are the following:</p>
<ul>
<li>Increased workgroup size to 1024. This increases available shared memory per-bin and also improves caching efficiency.</li>
<li>Per-workgroup scratch buffer is much bigger. Currently, 768 KB are used for scratch buffer. This will fit 128K tri-block-rows (16K per block-row) and 128K tri-half-blocks (4K per half-block).</li>
<li>In phase 2, tri-half-blocks are generated and sorted directly. The amount of space in shared memory required to generate and sort tri-half-blocks may be much bigger than in the low-rasterizer. Because of that, shared memory is allocated dynamically for this task and the number of subgroups working on a given half-block may vary as well.</li>
</ul>
<h2 id="3-results"><a class="anchor" name="3-results" href="#3-results"><span class="octicon octicon-link"></span></a>3. Results</h2>
<h3 id="test-scenes"><a class="anchor" name="test-scenes" href="#test-scenes"><span class="octicon octicon-link"></span></a>Test scenes</h3>
<p>12 different scenes were used during the evaluation of LucidRaster. To simplify the renderer all textures are packed into texture atlases. Each scene can use at most 2 atlases: one opaque and one transparent. Block compression is used: BC1 for opaque and BC3 for transparent atlases.</p>
<p>Triangles are grouped into quads using greedy maximal independent set algorithm <a href="#refs-halldorsson-1997">[Halldorsson 1997]</a>. The algorithm is performed on a graph where quads are treated as nodes and triangles (which are shared by quads) as edges. In most scenes this gives good results with on average about 5% of quads being degenerate.</p>
<table style="width:100%; font-size:0.8em">
  <tbody><tr><td><a href="https://nadult.github.io/images/lucid/scenes/boxes.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/boxes.jpg" alt="boxes_image" width="200"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/scenes/bunny.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/bunny.jpg" alt="bunny_image" width="200"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/scenes/conference.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/conference.jpg" alt="conference_image" width="200"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/scenes/dragon.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/dragon.jpg" alt="dragon_image" width="200"></a></td></tr>
  <tr style="text-align:center;vertical-align:top">
      <td>Boxes (12K tris)<br>6K quads (0% degenerate)<br>100% quads visible</td>
      <td>Bunny (144K tris)<br>72K quads (0.3% degenerate)<br>40% quads visible<br>Backface culling on</td>
      <td>Conference (331K tris)<br>167K quads (1.9% degenerate)<br>6% quads visible<br>Backface culling on</td>
      <td>Dragon (871K tris)<br>438K quads (0.9% degenerate)<br>~42% quads visible<br>Backface culling on</td></tr>
  <tr><td><a href="https://nadult.github.io/images/lucid/scenes/gallery.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/gallery.jpg" alt="gallery_image" width="200"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/scenes/hairball.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/hairball.jpg" alt="hairball_image" width="200"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/scenes/powerplant.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/powerplant.jpg" alt="powerplant_image" width="200"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/scenes/san_miguel.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/san_miguel.jpg" alt="san_miguel_image" width="200"></a></td></tr>
  <tr style="text-align:center;vertical-align:top">
      <td>Gallery (999K tris)<br>513K quads (5.2% degenerate)<br>60% quads visible</td>
      <td>Hairball (2880K tris)<br>1495K quads (7.4% degenerate)<br>99% quads visible</td>
      <td>Powerplant (12759K tris)<br>6402K quads (0.7% degenerate)<br>15% quads visible<br>Backface culling on</td>
      <td>San miguel (5617K tris)<br>3069K quads (17% degenerate)<br>~34% quads visible</td></tr>
  <tr><td><a href="https://nadult.github.io/images/lucid/scenes/scrub_pine.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/scrub_pine.jpg" alt="scrub_pine_image" width="200"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/scenes/sponza.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/sponza.jpg" alt="sponza_image" width="200"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/scenes/teapot.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/teapot.jpg" alt="teapot_image" width="200"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/scenes/white_oak.jpg">
          <img src="https://nadult.github.io/images/lucid/scenes_cropped/white_oak.jpg" alt="white_oak_image" width="200"></a></td></tr>
  <tr style="text-align:center;vertical-align:top">
      <td>Scrub pine (527 tris)<br>289 quads (18% degenerate)<br>100% quads visible</td>
      <td>Sponza (262K tris)<br>132K quads (1.5% degenerate)<br>18% quads visible</td>
      <td>Teapot (16K tris)<br>8K quads (0.1% degenerate)<br>100% quads visible</td>
      <td>White oak (37K tris)<br>19K quads (10% degenerate)<br>53% quads visible</td></tr>
</tbody></table>

<h3 id="performance-results"><a class="anchor" name="performance-results" href="#performance-results"><span class="octicon octicon-link"></span></a>Performance results</h3>
<p>LucidRaster performance was compared with simple renderer which renders all triangles using hardware with alpha blending on. <strong>SW</strong>, <strong>HW</strong> represent, respectively, LucidRaster and simple renderer running times in microseconds. <strong>S/THB</strong> is the average number of samples divided by the number of tri-half-blocks.</p>
<p>The fragment shader is almost identical in both renderers, with the main differences in vertex attribute retrieval and interpolation. Fragment shader code is available at GitHub:<br><a href="https://github.com/nadult/lucid/blob/main/data/shaders/simple_material.glsl"></a><a href="https://github.com/nadult/lucid/blob/main/data/shaders/simple_material.glsl">https://github.com/nadult/lucid/blob/main/data/shaders/simple_material.glsl</a>  </p>
<p>Measurements were gathered in 'mixed' mode where in a single frame both simple and lucid renderer were running one after another. Timings shown in tables are averages of samples gathered over several seconds for each scene.</p>
<p>Measurements on AMD Radeon RX 6700 XT were done on linux, because it seems that the latest AMD Vulkan drivers for linux have better subgroup support. Specifically, windows drivers didn't support VK_EXT_subgroup_size_control and some shaders which used subgroup instructions were working several times slower than on linux.</p>
<table style="text-align:right; font-family: monospace; font-size:0.9em;">
  <tbody><tr> <th colspan="6">NVidia GTX 3050 TI, Windows 10, 2560x1330</th> <th colspan="4" style="text-align:center">LucidRaster (SW) stages</th> </tr>
  <tr> <th>     Scene</th> <th>Samples</th> <th>S/THB</th> <th>   SW</th> <th>  HW</th> <th>SW/HW</th><th>setup</th> <th>binning</th> <th>low_raster</th> <th>hi_raster</th> </tr>
  <tr> <td>Boxes     </td> <td> 12.11M</td> <td>17.91</td> <td>1707 </td> <td> 401</td> <td>4.26</td> <td> 24  </td> <td>    53 </td> <td>      1609</td> <td>        4</td> </tr>
  <tr> <td>Bunny     </td> <td>  0.74M</td> <td> 3.33</td> <td>350  </td> <td>  78</td> <td>4.49</td> <td> 53  </td> <td>    38 </td> <td>       234</td> <td>        4</td> </tr>
  <tr> <td>Conference</td> <td>  5.31M</td> <td>16.75</td> <td>1158 </td> <td> 226</td> <td>5.12</td> <td> 58  </td> <td>    76 </td> <td>      1002</td> <td>        4</td> </tr>
  <tr> <td>Dragon    </td> <td>  0.67M</td> <td> 1.25</td> <td>837  </td> <td> 248</td> <td>3.38</td> <td> 328 </td> <td>    51 </td> <td>       302</td> <td>      136</td> </tr>
  <tr> <td>Gallery   </td> <td>  4.89M</td> <td> 3.07</td> <td>2621 </td> <td> 678</td> <td>3.87</td> <td> 771 </td> <td>    78 </td> <td>      1427</td> <td>      324</td> </tr>
  <tr> <td>Hairball  </td> <td> 22.00M</td> <td> 2.89</td> <td>11518</td> <td>3564</td> <td>3.23</td> <td> 1756</td> <td>    244</td> <td>       355</td> <td>     9146</td> </tr>
  <tr> <td>Powerplant</td> <td> 18.03M</td> <td> 3.60</td> <td>10121</td> <td>4761</td> <td>2.13</td> <td> 2720</td> <td>    346</td> <td>       838</td> <td>     6201</td> </tr>
  <tr> <td>San miguel</td> <td> 21.27M</td> <td> 6.57</td> <td>9234 </td> <td>3667</td> <td>2.52</td> <td> 2391</td> <td>    216</td> <td>      2261</td> <td>     4349</td> </tr>
  <tr> <td>Scrub pine</td> <td>  3.26M</td> <td>24.44</td> <td>575  </td> <td> 193</td> <td>2.98</td> <td> 15  </td> <td>    61 </td> <td>       474</td> <td>        4</td> </tr>
  <tr> <td>Sponza    </td> <td> 24.00M</td> <td>19.80</td> <td>3910 </td> <td>1690</td> <td>2.31</td> <td> 98  </td> <td>    130</td> <td>      3658</td> <td>        3</td> </tr>
  <tr> <td>Teapot    </td> <td>  1.71M</td> <td> 8.53</td> <td>373  </td> <td> 111</td> <td>3.36</td> <td> 23  </td> <td>    40 </td> <td>       285</td> <td>        4</td> </tr>
  <tr> <td>White oak </td> <td>122.00M</td> <td>26.95</td> <td>13005</td> <td>6049</td> <td>2.15</td> <td> 37  </td> <td>    189</td> <td>     12759</td> <td>        3</td> </tr>
  <tr style="font-weight: bold;"> <td colspan="5">Averages:</td>                        <td>3.32</td> <td>  14%</td> <td>     5%</td> <td>       60%</td> <td>      18%</td> </tr>

  <tr style="border-bottom:1px solid black"> <td colspan="100%"></td> </tr>

  <tr> <th colspan="6">AMD Radeon RX 6700 XT, Ubuntu 22.04, 1920x1031</th> <th colspan="4" style="text-align:center">LucidRaster (SW) stages</th> </tr>
  <tr> <th>     Scene</th> <th>Samples</th> <th> S/HB</th> <th>  SW</th> <th>  HW</th> <th>SW/HW</th><th>setup</th> <th>binning</th> <th>low_raster</th> <th>hi_raster</th> </tr>
  <tr> <td>Boxes     </td> <td>  7.28M</td> <td>15.80</td> <td> 546</td> <td> 202</td> <td>2.70</td> <td>   10</td> <td>     17</td> <td>       508</td> <td>        6</td> </tr>
  <tr> <td>Bunny     </td> <td>  0.44M</td> <td> 2.48</td> <td> 131</td> <td>  32</td> <td>4.09</td> <td>   17</td> <td>     19</td> <td>        84</td> <td>        5</td> </tr>
  <tr> <td>Conference</td> <td>  3.11M</td> <td>14.77</td> <td> 370</td> <td> 101</td> <td>3.66</td> <td>   19</td> <td>     44</td> <td>       296</td> <td>        5</td> </tr>
  <tr> <td>Dragon    </td> <td>  0.40M</td> <td> 1.15</td> <td> 272</td> <td>  95</td> <td>2.86</td> <td>   88</td> <td>     25</td> <td>        68</td> <td>       85</td> </tr>
  <tr> <td>Gallery   </td> <td>  2.86M</td> <td> 2.48</td> <td> 907</td> <td> 224</td> <td>4.05</td> <td>  186</td> <td>     31</td> <td>       453</td> <td>      232</td> </tr>
  <tr> <td>Hairball  </td> <td> 13.22M</td> <td> 2.38</td> <td>4388</td> <td>1084</td> <td>4.05</td> <td>  991</td> <td>    116</td> <td>       152</td> <td>     3123</td> </tr>
  <tr> <td>Powerplant</td> <td> 10.83M</td> <td> 3.27</td> <td>3532</td> <td>1533</td> <td>2.30</td> <td> 1260</td> <td>    144</td> <td>       237</td> <td>     1885</td> </tr>
  <tr> <td>San miguel</td> <td> 12.59M</td> <td> 5.65</td> <td>3396</td> <td>1066</td> <td>3.19</td> <td> 1127</td> <td>     97</td> <td>       653</td> <td>     1513</td> </tr>
  <tr> <td>Scrub pine</td> <td>  1.96M</td> <td>22.90</td> <td> 242</td> <td>  57</td> <td>4.25</td> <td>    6</td> <td>     24</td> <td>       200</td> <td>        6</td> </tr>
  <tr> <td>Sponza    </td> <td> 13.97M</td> <td>17.66</td> <td>1194</td> <td> 375</td> <td>3.18</td> <td>   33</td> <td>     55</td> <td>      1052</td> <td>       47</td> </tr>
  <tr> <td>Teapot    </td> <td>  1.03M</td> <td> 6.91</td> <td> 147</td> <td>  50</td> <td>2.94</td> <td>   11</td> <td>     18</td> <td>       107</td> <td>        5</td> </tr>
  <tr> <td>White oak </td> <td> 71.41M</td> <td>25.68</td> <td>3500</td> <td>1624</td> <td>2.16</td> <td>   11</td> <td>     80</td> <td>      3397</td> <td>        7</td> </tr>
  <tr style="font-weight: bold;"> <td colspan="5">Averages:</td>                       <td>3.29</td> <td>  15%</td> <td>     7%</td> <td>       57%</td> <td>      20%</td> </tr>
</tbody></table>


<h4 id="alpha-threshold"><a class="anchor" name="alpha-threshold" href="#alpha-threshold"><span class="octicon octicon-link"></span></a>Alpha threshold</h4>
<p>When 'alpha_threshold' flag is enabled, shading stops once enough alpha value was accumulated in a given pixel. Rendering of some scenes can be much faster when this flag is used, especially in cases when lots of samples are hidden beneath an almost opaque layer of samples. The following speedups were achieved:</p>
<table style="text-align:right; font-family: monospace; font-size:0.9em;">
  <tbody><tr> <th colspan="3">NVidia GTX 3050 TI, Windows 10, 2560x1330</th> <th colspan="2">alpha_threshold off<br><center>(default)</center></th> <th colspan="2">alpha_threshold on</th> </tr>
  <tr> <th>Scene     </th> <th>Scene opacity</th> <th>  HW</th> <th>   SW</th> <th>SW/HW</th> <th>   SW</th> <th>SW/HW</th> </tr>
  <tr> <td>Boxes     </td> <td>0.5          </td> <td> 401</td> <td> 1707</td> <td>4.26 </td> <td> 1288</td> <td> 3.21</td> </tr>
  <tr> <td>Boxes     </td> <td>0.8          </td> <td> 401</td> <td> 1707</td> <td>4.26 </td> <td> 1169</td> <td> 2.92</td> </tr>
  <tr> <td>Hairball  </td> <td>0.5          </td> <td>3564</td> <td>11518</td> <td>3.23 </td> <td> 9784</td> <td> 2.75</td> </tr>
  <tr> <td>Powerplant</td> <td>0.5          </td> <td>4761</td> <td>10121</td> <td>2.13 </td> <td> 9445</td> <td> 1.98</td> </tr>
  <tr> <td>White oak </td> <td>0.5          </td> <td>6049</td> <td>13005</td> <td>2.15 </td> <td>13129</td> <td> 2.17</td> </tr>
  <tr> <td>White oak </td> <td>0.8          </td> <td>6049</td> <td>13005</td> <td>2.15 </td> <td>11070</td> <td> 1.83</td> </tr>
</tbody></table>

<p>In other scenes the gains were negligible.</p>
<h3 id="rendering-errors"><a class="anchor" name="rendering-errors" href="#rendering-errors"><span class="octicon octicon-link"></span></a>Rendering errors</h3>
<p>Two-stage sorting technique fails in some cases. Those cases are rare and can be detected and dealt with properly. On the average number of invalid pixels is very small (0.17%, 0.02% with DF=8), so even if they were handled with a very slow shader, it shouldn't affect overall performance noticeably. LucidRaster currently doesn't handle those cases, but it will show invalid pixels when 'visualize_errors' flag is enabled.</p>
<p>The number of invalid pixels depends on the geometrical complexity nearby surface intersections in the scene and on the size of the depth filter. What follows is a table with error statistics for different depth filter sizes.</p>
<table style="text-align:right; font-family: monospace; font-size:0.9em;">
  <tbody><tr style="text-align:center"> <th></th> <th colspan="3">Invalid pixels (total)</th> <th colspan="3">Invalid pixels (percentage)</th> <th colspan="3">Rendering time compared to DF=3</th> </tr>
  <tr> <th>     Scene</th> <th> DF=3</th> <th>DF=8</th> <th>DF=12</th> <th>    DF=3</th> <th>DF=8</th> <th>DF=12</th> <th>DF=8</th> <th>DF=12</th></tr>
  <tr> <td>Boxes     </td> <td>    3</td> <td>   0</td> <td>    0</td> <td>&lt;0.01%</td> <td>         </td> <td>         </td> <td>102%</td> <td>115%</td> </tr>
  <tr> <td>Bunny     </td> <td>    1</td> <td>   0</td> <td>    0</td> <td>&lt;0.01%</td> <td>         </td> <td>         </td> <td>101%</td> <td>124%</td> </tr>
  <tr> <td>Conference</td> <td>   19</td> <td>   0</td> <td>    0</td> <td>&lt;0.01%</td> <td>         </td> <td>         </td> <td>104%</td> <td>127%</td> </tr>
  <tr> <td>Dragon    </td> <td>    0</td> <td>   0</td> <td>    0</td> <td>         </td> <td>         </td> <td>         </td> <td> 99%</td> <td>108%</td> </tr>
  <tr> <td>Gallery   </td> <td>   70</td> <td>   1</td> <td>    0</td> <td>&lt;0.01%</td> <td>&lt;0.01%</td> <td>         </td> <td>101%</td> <td>121%</td> </tr>
  <tr> <td>Hairball  </td> <td>14100</td> <td>1530</td> <td>  660</td> <td>    0.41%</td> <td>    0.04%</td> <td>    0.02%</td> <td>100%</td> <td>107%</td> </tr>
  <tr> <td>Powerplant</td> <td> 1800</td> <td>  15</td> <td>    3</td> <td>    0.05%</td> <td>&lt;0.01%</td> <td>&lt;0.01%</td> <td>100%</td> <td>106%</td> </tr>
  <tr> <td>San miguel</td> <td>17112</td> <td>4513</td> <td> 2828</td> <td>    0.50%</td> <td>    0.13%</td> <td>    0.08%</td> <td>103%</td> <td>112%</td> </tr>
  <tr> <td>Scrub pine</td> <td>  190</td> <td>   0</td> <td>    0</td> <td>    0.01%</td> <td>         </td> <td>         </td> <td>102%</td> <td>121%</td> </tr>
  <tr> <td>Sponza    </td> <td>  290</td> <td>   4</td> <td>    1</td> <td>    0.01%</td> <td>&lt;0.01%</td> <td>&lt;0.01%</td> <td>103%</td> <td>128%</td> </tr>
  <tr> <td>Teapot    </td> <td>    9</td> <td>   0</td> <td>    0</td> <td>&lt;0.01%</td> <td>         </td> <td>         </td> <td>103%</td> <td>124%</td> </tr>
  <tr> <td>White oak </td> <td>34780</td> <td>2850</td> <td>  905</td> <td>    1.02%</td> <td>    0.08%</td> <td>    0.03%</td> <td>103%</td> <td>116%</td> </tr>
  <tr style="font-weight: bold;"> <td colspan="4">Averages:</td>       <td>    0.17%</td> <td>    0.02%</td> <td>    0.01%</td> <td>102%</td> <td>117%</td> </tr>
</tbody></table>

<p>What follows is a visualization of errors in the most problematic areas of some scenes.</p>
<table style="width:100%; font-size:0.8em">
  <tbody><tr><th>Depth filter size = 3 (default)</th> <th>Depth filter size = 8</th> <th>Depth filter size = 12</th> </tr>

  <tr><td><a href="https://nadult.github.io/images/lucid/invalid/hairball_invalid3.png">
          <img src="https://nadult.github.io/images/lucid/invalid/hairball_invalid3.png" alt="hairball_invalid_image" width="240"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/invalid/hairball_invalid8.png">
          <img src="https://nadult.github.io/images/lucid/invalid/hairball_invalid8.png" alt="hairball_invalid_image" width="240"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/invalid/hairball_invalid12.png">
          <img src="https://nadult.github.io/images/lucid/invalid/hairball_invalid12.png" alt="hairball_invalid_image" width="240"></a></td></tr>

  <tr><td><a href="https://nadult.github.io/images/lucid/invalid/san_miguel_invalid3.png">
          <img src="https://nadult.github.io/images/lucid/invalid/san_miguel_invalid3.png" alt="san_miguel_invalid_image" width="240"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/invalid/san_miguel_invalid8.png">
          <img src="https://nadult.github.io/images/lucid/invalid/san_miguel_invalid8.png" alt="san_miguel_invalid_image" width="240"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/invalid/san_miguel_invalid12.png">
          <img src="https://nadult.github.io/images/lucid/invalid/san_miguel_invalid12.png" alt="san_miguel_invalid_image" width="240"></a></td></tr>

  <tr><td><a href="https://nadult.github.io/images/lucid/invalid/white_oak_invalid3.png">
          <img src="https://nadult.github.io/images/lucid/invalid/white_oak_invalid3.png" alt="white_oak_invalid_image" width="240"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/invalid/white_oak_invalid8.png">
          <img src="https://nadult.github.io/images/lucid/invalid/white_oak_invalid8.png" alt="white_oak_invalid_image" width="240"></a></td>
      <td><a href="https://nadult.github.io/images/lucid/invalid/white_oak_invalid12.png">
          <img src="https://nadult.github.io/images/lucid/invalid/white_oak_invalid12.png" alt="white_oak_invalid_image" width="240"></a></td></tr>
</tbody></table>

<h3 id="4-future-work"><a class="anchor" name="4-future-work" href="#4-future-work"><span class="octicon octicon-link"></span></a>4. Future work</h3>
<h4 id="msaa"><a class="anchor" name="msaa" href="#msaa"><span class="octicon octicon-link"></span></a>MSAA</h4>
<ul>
<li>Enabling 4x or 16x MSAA shouldn't be hard in LucidRaster.</li>
<li>MSAA would mostly affect first and second phase of raster stage; more space would be needed to store triangle sample ranges (~2x more for 4x MSAA and ~4x more for 16x MSAA).</li>
<li>It should be possible to achieve high quality MSAA just by modifying blending and without big increase in number of samples (alpha values for samples would be affected by number of MSAA samples).</li>
</ul>
<h4 id="memory-usage"><a class="anchor" name="memory-usage" href="#memory-usage"><span class="octicon octicon-link"></span></a>Memory usage</h4>
<p>Currently LucidRaster uses a lot of memory, but most storages in rasterization stage are mostly empty most of the time. Dynamic allocation of storage memory should allow for great reduction in memory usage there.</p>
<h4 id="meshlets"><a class="anchor" name="meshlets" href="#meshlets"><span class="octicon octicon-link"></span></a>Meshlets</h4>
<ul>
<li>Meshlets should be able to greatly improve performance of setup &amp; binning stages.</li>
<li>Possibly with meshlets memory requirements could be decreased, because more compressed storage is possible for pre-computed data.</li>
</ul>
<h4 id="multi-material-support"><a class="anchor" name="multi-material-support" href="#multi-material-support"><span class="octicon octicon-link"></span></a>Multi-material support</h4>
<ul>
<li>Currently uber shader has to be used.</li>
<li>Not easy, but possible: handling different types of inputs efficiently.</li>
<li>Problems: register pressure with complex materials, thread divergence.</li>
<li>On the plus side: with complex materials rasterization time is less of an issue.</li>
</ul>
<h4 id="optimizations"><a class="anchor" name="optimizations" href="#optimizations"><span class="octicon octicon-link"></span></a>Optimizations</h4>
<ul>
<li>Currently lucid uses 32x32 bins, but it could be beneficial to use 64x64 bins in areas with low density of triangles and 16x16 in high-density areas.</li>
<li>It should be possible to run high-rasterizers and low-rasterizers at the same time; it would increase parallelism, but it would also require.</li>
<li>There are more places in code where parallelism could be improved, but it requires more work.</li>
</ul>
<h2 id="5-vulkan-glossary"><a class="anchor" name="5-vulkan-glossary" href="#5-vulkan-glossary"><span class="octicon octicon-link"></span></a>5. Vulkan glossary</h2>
<p><strong>Workgroup</strong>: <a name="glossary-workgroup"> A collection of compute shader threads which execute the same program in parallel. Threads within a workgroup can share resources and synchronise their execution.<br><strong>Subgroup</strong>: </a><a name="glossary-subgroup"> A collection of compute shader threads which can effectively communicate and synchronize.<br><strong>Global memory</strong>: </a><a name="glossary-global-memory"> Off-chip GPU memory (DRAM). Accessible in Vulkan's compute shaders mainly through buffers, images and textures. It's global in the sense that it can be shared between different workgroups and pipeline stages.<br><strong>Shared memory</strong>: </a><a name="glossary-shared-memory"> Fast, small on-chip GPU memory shared across all threads within a workgroup.  </a></p><a name="glossary-shared-memory">
<p>More information about Vulkan and compute shaders can be found in:</p>
</a><ul><a name="glossary-shared-memory">
</a><li><a name="glossary-shared-memory">Vulkan 1.3 specification: </a><a href="https://registry.khronos.org/vulkan/specs/1.3-extensions/html/vkspec.html">https://registry.khronos.org/vulkan/specs/1.3-extensions/html/vkspec.html</a></li>
<li>Compute shader 101 glossary: <a href="https://github.com/googlefonts/compute-shader-101/blob/main/docs/glossary.md">https://github.com/googlefonts/compute-shader-101/blob/main/docs/glossary.md</a></li>
<li>Vulkan subgroup tutorial: <a href="https://www.khronos.org/blog/vulkan-subgroup-tutorial">https://www.khronos.org/blog/vulkan-subgroup-tutorial</a></li>
</ul>
<h2 id="6-references"><a class="anchor" name="6-references" href="#6-references"><span class="octicon octicon-link"></span></a>6. References</h2>
<style>
.markdown-body .refs td { font-size:0.9em; }
.markdown-body .refs td:target { background-color: #CCDDFF; }
.markdown-body .refs td { border: none; }
.markdown-body .refs tr:nth-child(1) { border-top: none; }
.markdown-body .refs tr:nth-child(2n) {  background-color: transparent; }
.markdown-body .refs td:nth-child(1) { font-weight: bold; text-align: right; vertical-align:top; }
</style>

<table class="refs" style="border:none;" cellspacing="0" cellpadding="0">
  <tbody><tr><td id="refs-carpenter-1984">[Carpenter 1984]</td>   <td><strong>"The A-buffer, an Antialiased Hidden Surface Method"</strong><br>Loren Carpenter</td></tr>
  <tr><td id="refs-molnar-1994">[Molnar 1994]</td>      <td><strong>"A Sorting Classification of Parallel Rendering"</strong><br>Steven Molnar, Michael Cox, David Ellsworth, Henry Fuchs</td></tr>
  <tr><td id="refs-blinn-1996">[Blinn 1996]</td>       <td><strong>"Calculating Screen Coverage"</strong><br>Jim Blinn's Corner</td></tr>
  <tr><td id="refs-halldorsson-1997">[Halldorsson 1997]</td> <td><strong>"Greed is good: Approximating independent sets in sparse and bounded-degree graphs"</strong><br>M. HalldÃ³rsson, J. Radhakrishnan</td></tr>
  <tr><td id="refs-everitt-2001">[Everitt 2001]</td>     <td><strong>"Interactive Order-Independent Transparency"</strong><br>Cass Everitt</td></tr>
  <tr><td id="refs-abrash-2009">[Abrash 2009]</td>      <td><strong>"Rasterization on Larrabee" (Dr Dobbs article)</strong><br>Michael Abrash</td></tr>
  <tr><td id="refs-liu-2010">[Liu 2010]</td>         <td><strong>"FreePipe: a Programmable Parallel Rendering Architecture for Efficient Multi-Fragment Effects"</strong><br>Fang Liu, Meng-Cheng Huang, Xue-Hui Liu, En-Hua Wu</td></tr>
  <tr><td id="refs-laine-2011">[Laine 2011]</td>       <td><strong>"High-Performance Software Rasterization on GPUs"</strong><br>Samuli Laine, Tero Karras</td></tr>
  <tr><td id="refs-gupta-2012">[Gupta 2012]</td>       <td><strong>"A Study of Persistent Threads Style GPU Programming for GPGPU Workloads"</strong><br>Kshitij Gupta, Jeff A. Stuart, John D. Owens</td></tr>
  <tr><td id="refs-davidovic-2012">[Davidovic 2012]</td>   <td><strong>"3D Rasterization: A Bridge between Rasterization and Ray Casting"</strong><br>Tomas Davidovic, Thomas Engelhardt, Iliyan Georgiev, Philipp Slusallek, Carsten Dachsbacher</td></tr>
  <tr><td id="refs-demouth-2013">[Demouth 2013]</td>     <td><strong>"Shuffle: Tips and Tricks" (NVIDIA GTC 2013 Conference presentation)</strong><br>Julien Demouth</td></tr>
  <tr><td id="refs-mcguire-2013">[McGuire 2013]</td>     <td><strong>"Weighted Blended Order-Independent Transparency"</strong><br>Morgan McGuire, Louis Bavoil</td></tr>
  <tr><td id="refs-knowles-2013">[Knowles 2013]</td>     <td><strong>"Backwards Memory Allocation and Improved OIT"</strong><br>Pyarelal Knowles, Geoff Leach, Fabio Zambetta</td></tr>
  <tr><td id="refs-knowles-2014">[Knowles 2014]</td>     <td><strong>"Fast sorting for exact OIT of complex scenes"</strong><br>Pyarelal Knowles, Geoff Leach, Fabio Zambetta</td></tr>
  <tr><td id="refs-salvi-2014">[Salvi 2014]</td>       <td><strong>"Multi-Layer Alpha Blending"</strong><br>Marco Salvi, Karthik Vaidyanathan</td></tr>
  <tr><td id="refs-wyman-2016">[Wyman 2016]</td>       <td><strong>"Exploring and Expanding the Continuum of OIT Algorithms"</strong><br>Chris Wyman</td></tr>
  <tr><td id="refs-kohler-2016">[KÃ¶hler 2016]</td>      <td><strong>"Practical Order Independent Transparency"</strong><br>Johan KÃ¶hler</td></tr>
  <tr><td id="refs-kenzel-2018">[Kenzel 2018]</td>      <td><strong>"A High-Performance Software Graphics Pipeline Architecture for the GPU"</strong><br>Michael Kenzel, Bernhard Kerbl, Dieter Schmalstieg, Markus Steinberger</td></tr> 
  <tr><td id="refs-peters-2018">[Peters 2018]</td>      <td><strong>"Moment-Based Order-Independent Transparency"</strong><br>Cedrick MÃ¼nstermann, Stefan Krumpen, Reinhard Klein, Christoph Peters</td></tr>
  <tr><td id="refs-vasilakis-2020">[Vasilakis 2020]</td>   <td><strong>"A Survey of Multifragment Rendering"</strong><br>A. A. Vasilakis, K. Vardis, G. Papaioannou</td></tr>
  <tr><td id="refs-karis-2021">[Karis 2021]</td>       <td><strong>"Nanite, A deep dive" (Siggraph 2021 presentation)</strong><br>Brian Karis, Rune Stubbe, Graham Wihlidal</td></tr>

  <!-- <tr><td id="refs-"     >[]</td>      <td><strong>" "</strong><br/> </td></tr> -->
</tbody></table></div></body></html>